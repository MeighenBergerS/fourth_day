{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name: example_prob_model_atten_test.ipynb\n",
    "Authors: Stephan Meighen-Berger\n",
    "Example how to use the probabilistic model to get an estimate of the attenuation length\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.interpolate import RectBivariateSpline, UnivariateSpline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding path to module\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fourth_day.pdfs import construct_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picture path\n",
    "PICS = '../pics/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting standards\n",
    "std_size = 6.\n",
    "fontsize = 20.\n",
    "lw=1.\n",
    "h_length=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = pickle.load( open(\"offcenter_0.p\", \"rb\" ) )\n",
    "data_1 = pickle.load( open(\"offcenter_1.p\", \"rb\" ) )\n",
    "data_2 = pickle.load( open(\"offcenter_2.p\", \"rb\" ) )\n",
    "data_3 = pickle.load( open(\"offcenter_3.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_alpha = 0\n",
    "counts_0, edges_0 = np.histogram(\n",
    "    data_0['x_arr'][id_alpha],\n",
    "    bins=np.linspace(0., 26., 131),\n",
    "    weights=1./data_0['norm'][id_alpha]\n",
    ")\n",
    "counts_1, edges_1 = np.histogram(\n",
    "    data_1['x_arr'][id_alpha],\n",
    "    bins=np.linspace(0., 26., 131),\n",
    "    weights=1./data_1['norm'][id_alpha]\n",
    ")\n",
    "counts_2, edges_2 = np.histogram(\n",
    "    data_2['x_arr'][id_alpha],\n",
    "    bins=np.linspace(0., 26., 131),\n",
    "    weights=1./data_2['norm'][id_alpha]\n",
    ")\n",
    "counts_3, edges_3 = np.histogram(\n",
    "    data_3['x_arr'][id_alpha],\n",
    "    bins=np.linspace(0., 26., 131),\n",
    "    weights=1./data_3['norm'][id_alpha]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spl_prob = RectBivariateSpline(\n",
    "    (edges_0[1:] + edges_0[:-1]) / 2.,\n",
    "    np.array([0., 1., 2., 3.]),\n",
    "    np.array([counts_0, counts_1, counts_2, counts_3]).T, s=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "detector_position = np.array([0., 0.])\n",
    "dens = 5e-1\n",
    "acceptance_range = np.array([30., 90.])\n",
    "simulation_step = 0.1\n",
    "simulation_time = 10000.\n",
    "run_counts = 10\n",
    "wavelengths = np.linspace(300., 600., 301)\n",
    "emission_time = 100.\n",
    "photon_counts = 1e10\n",
    "efficiency = 0.1\n",
    "water_vel = 0.5 * simulation_step\n",
    "rest_time = 100. / simulation_step\n",
    "species = np.array([\"Species 1\", \"Species 2\"])\n",
    "gamma_test = construct_pdf(\n",
    "    {\"class\": \"Gamma\",\n",
    "     \"mean\": 0.5 / simulation_step,\n",
    "     \"sd\": 0.45 / simulation_step\n",
    "    })\n",
    "gamma_test_2 = construct_pdf(\n",
    "    {\"class\": \"Gamma\",\n",
    "     \"mean\": 0.2 / simulation_step,\n",
    "     \"sd\": 0.15 / simulation_step\n",
    "    })\n",
    "gauss_test = construct_pdf(\n",
    "    {\"class\": \"Normal\",\n",
    "     \"mean\": 450.,\n",
    "     \"sd\": 50.\n",
    "    })\n",
    "min_y = 0.\n",
    "max_y = 3.\n",
    "max_x = 26.\n",
    "starting_pop = 2\n",
    "pop_size = starting_pop\n",
    "injection_count = dens * (max_y - min_y) * water_vel\n",
    "expected_counts = int(injection_count * simulation_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing pdfs\n",
    "norm_time_series_1 = (\n",
    "    gamma_test.pdf(np.arange(0., emission_time, simulation_step)) /\n",
    "    np.trapz(gamma_test.pdf(np.arange(0., emission_time, simulation_step)),\n",
    "             np.arange(0., emission_time, simulation_step))\n",
    ")\n",
    "norm_time_series_2 = (\n",
    "    gamma_test_2.pdf(np.arange(0., emission_time, simulation_step)) /\n",
    "    np.trapz(gamma_test.pdf(np.arange(0., emission_time, simulation_step)),\n",
    "             np.arange(0., emission_time, simulation_step))\n",
    ")\n",
    "norm_time_series_1 = norm_time_series_1 * photon_counts\n",
    "norm_time_series_2 = norm_time_series_2 * photon_counts\n",
    "norm_dic = {\n",
    "    species[0]: norm_time_series_1,\n",
    "    species[1]: norm_time_series_2\n",
    "}\n",
    "norm_wavelengths = (\n",
    "    gauss_test.pdf(wavelengths) /\n",
    "    np.trapz(gauss_test.pdf(wavelengths), wavelengths)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The attenuation function\n",
    "attenuation_vals = np.array([\n",
    "    [\n",
    "        299.,\n",
    "        329.14438502673795, 344.11764705882354, 362.2994652406417,\n",
    "        399.44415494181, 412.07970421102266, 425.75250006203635,\n",
    "        442.53703565845314, 457.1974490682151, 471.8380108687561,\n",
    "        484.3544504826423, 495.7939402962853, 509.29799746891985,\n",
    "        519.6903148961513, 530.0627807141617, 541.5022705278046,\n",
    "        553.9690811186382, 567.4929899004939, 580.9771954639073,\n",
    "        587.1609717362714, 593.3348222040249, 599.4391920395047,\n",
    "        602.4715253480235\n",
    "    ],\n",
    "    [\n",
    "        0.8,\n",
    "        0.6279453220864465,0.3145701363176568,\n",
    "        0.12591648888305143,0.026410321551339357, 0.023168667048510762,\n",
    "        0.020703255370450736, 0.019552708373076478,\n",
    "        0.019526153330089138, 0.020236306473695613,\n",
    "        0.02217620815962483, 0.025694647290888873,\n",
    "        0.031468126242251794, 0.03646434475343956,\n",
    "        0.04385011375530569, 0.05080729755501162,\n",
    "        0.061086337538657706, 0.07208875589035815, 0.09162216168767365,\n",
    "        0.11022281058708046, 0.1350811713674855, 0.18848851206491904,\n",
    "        0.23106528395398912\n",
    "    ]\n",
    "])\n",
    "atten_spl = UnivariateSpline(attenuation_vals[0], attenuation_vals[1], k=1, s=0)\n",
    "atten_vals = atten_spl(wavelengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_func(atten_func, pop_size, id_wave=200):\n",
    "    injection_times = np.sort(np.random.randint(int(simulation_time / simulation_step), size=expected_counts))\n",
    "    unqiue_times, unique_counts = np.unique(injection_times, return_counts=True)\n",
    "    # The population\n",
    "    population = pd.DataFrame(\n",
    "        {\n",
    "            \"species\": None,\n",
    "            \"pos_x\": 0.,\n",
    "            \"pos_y\": 0.,\n",
    "            \"observed\": True,\n",
    "            \"flashing\": False,\n",
    "            \"can_flash\": True,\n",
    "            \"rest_time\": 0,\n",
    "        },\n",
    "        index=np.arange(starting_pop),\n",
    "    )\n",
    "    population.loc[:, 'pos_y'] = np.random.uniform(min_y, max_y, starting_pop)\n",
    "    # Species\n",
    "    if len(species) > 1:\n",
    "        pop_index_sample = np.random.randint(\n",
    "            0, len(species), starting_pop\n",
    "        )\n",
    "    elif len(species) == 1:\n",
    "        pop_index_sample = np.zeros(starting_pop, dtype=np.int)\n",
    "    population.loc[:, 'species'] = (\n",
    "        species[pop_index_sample]\n",
    "    )\n",
    "    statistics = list(range(int(simulation_time / simulation_step)))\n",
    "    for i in range(int(simulation_time / simulation_step)):\n",
    "        counter = 0\n",
    "        # Resetting the flash\n",
    "        population.loc[:, 'flashing'] = False\n",
    "        if i in unqiue_times:\n",
    "            inject = unique_counts[counter]\n",
    "            for j in range(inject):\n",
    "                if len(species) > 1:\n",
    "                    pop_index_sample = np.random.randint(\n",
    "                        0, len(species), 1\n",
    "                    )\n",
    "                elif len(species) == 1:\n",
    "                    pop_index_sample = np.zeros(1, dtype=np.int)\n",
    "                population.loc[pop_size + (j+1)] = [\n",
    "                    species[pop_index_sample][0],\n",
    "                    0.,\n",
    "                    np.random.uniform(min_y, max_y),\n",
    "                    True,\n",
    "                    False,\n",
    "                    True,\n",
    "                    0\n",
    "                ]\n",
    "                pop_size += 1\n",
    "            counter += 1\n",
    "        # Injection only according to array\n",
    "        observation_mask = population.loc[:, 'observed']\n",
    "        # propagation\n",
    "        population.loc[observation_mask, 'pos_x'] = population.loc[observation_mask, 'pos_x'] + water_vel\n",
    "        # Checking if should emit\n",
    "        prob_arr = spl_prob(\n",
    "            population.loc[observation_mask, 'pos_x'].values,\n",
    "            population.loc[observation_mask, 'pos_y'].values, grid=False)\n",
    "        prob_arr[prob_arr < 0.] = 0.\n",
    "        flash_mask = np.logical_and(np.array(np.random.binomial(1, prob_arr, len(prob_arr)), dtype=bool),\n",
    "                                    population.loc[observation_mask, 'can_flash'].values)\n",
    "        population.loc[observation_mask, 'flashing'] += flash_mask\n",
    "        can_flash_mask =  population.loc[:, 'flashing'].values\n",
    "        population.loc[can_flash_mask, 'can_flash'] = False\n",
    "        # Counting the rest\n",
    "        resting_mask = population.loc[:, 'can_flash'].values\n",
    "        population.loc[~resting_mask, 'rest_time'] += 1\n",
    "        # Checking if can flash again\n",
    "        flash_mask = np.greater(population.loc[:, 'rest_time'], rest_time)\n",
    "        population.loc[flash_mask, 'rest_time'] = 0\n",
    "        population.loc[flash_mask, 'can_flash'] = True\n",
    "        # Observed\n",
    "        new_observation_mask = np.less(population.loc[observation_mask, 'pos_x'], max_x)\n",
    "        population.loc[observation_mask, 'observed'] = new_observation_mask\n",
    "        statistics[i] = population.copy()\n",
    "    # Applying emission pdf\n",
    "    # And propagating\n",
    "    arriving_light = np.zeros((int(simulation_time / simulation_step), len(wavelengths)))\n",
    "    for id_step, pop in enumerate(statistics):\n",
    "        flashing_mask = pop.loc[:, 'flashing'].values\n",
    "        if np.sum(flashing_mask) > 0:\n",
    "            x_arr = pop.loc[flashing_mask, 'pos_x'].values\n",
    "            y_arr = pop.loc[flashing_mask, 'pos_y'].values\n",
    "            species_arr = pop.loc[flashing_mask, \"species\"].values\n",
    "            distances = np.sqrt(\n",
    "                (x_arr - detector_position[0])**2. +\n",
    "                (y_arr - detector_position[1])**2.\n",
    "            )\n",
    "            angles = np.array(\n",
    "                np.arctan2(\n",
    "                    (y_arr - detector_position[1]),\n",
    "                    (x_arr - detector_position[0]))\n",
    "            )\n",
    "            angles = np.degrees(angles)\n",
    "            outside_minus = np.less(angles, acceptance_range[0])\n",
    "            outside_plus = np.greater(angles, acceptance_range[1])\n",
    "            angle_check = np.logical_and(~outside_minus, ~outside_plus)\n",
    "            angle_squash = angle_check.astype(float)\n",
    "            atten_facs = np.array([\n",
    "                np.exp(-distances[id_flash] * atten_func) / (4. * np.pi * distances[id_flash]**2.)\n",
    "                for id_flash in range(np.sum(flashing_mask))\n",
    "            ])\n",
    "            curr_pulse = np.array([\n",
    "                [\n",
    "                    (norm_time * norm_wavelengths * atten_facs[id_flash]) * efficiency * angle_squash[id_flash]\n",
    "                    for norm_time in norm_dic[species_arr[id_flash]]\n",
    "                ]\n",
    "                for id_flash in range(np.sum(flashing_mask))\n",
    "            ])\n",
    "            # Checking if end is being overshot\n",
    "            if id_step+int(emission_time / simulation_step) <= len(arriving_light):\n",
    "                arriving_light[id_step:id_step+int(emission_time / simulation_step), :] += (\n",
    "                    np.sum(curr_pulse, axis=0)\n",
    "                )\n",
    "            else:\n",
    "                arriving_light[id_step:id_step+int(emission_time / simulation_step), :] += (\n",
    "                    np.sum(curr_pulse, axis=0)[0:len(arriving_light) - (id_step+int(emission_time / simulation_step))]\n",
    "                )\n",
    "    data_test = arriving_light[:, id_wave]\n",
    "    x_grid = np.arange(0., simulation_time, simulation_step)\n",
    "    peaks, properties = find_peaks(data_test, prominence=1, width=20)\n",
    "    return [\n",
    "        len(peaks), properties[\"prominences\"],\n",
    "        x_grid[properties[\"right_ips\"].astype(int)] - x_grid[properties[\"left_ips\"].astype(int)]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(atten_func, number_of_runs, id_wave=200):\n",
    "    pop_size = starting_pop\n",
    "    number_of_peaks = []\n",
    "    peak_heights = []\n",
    "    peak_widths = []\n",
    "    def map_func(counter):\n",
    "        return run_func(atten_func, pop_size, id_wave)\n",
    "    res = np.array([map_func(count) for count in tqdm(range(number_of_runs))])\n",
    "    return res[:, 0], res[:, 1], res[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]C:\\Users\\steph\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:178: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  f\"evaluating in Python space because the {repr(op_str)} \"\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 10/10 [3:02:11<00:00, 1093.19s/it]\n"
     ]
    }
   ],
   "source": [
    "number_of_peaks_base, peak_heights_base, peak_widths_base = evaluation(atten_vals, run_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([number_of_peaks_base, peak_heights_base, peak_widths_base],\n",
    "            open(\"base_sim.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_heights = np.logspace(2, 6, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_width = np.linspace(0., 10., 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_peaks_base_mean = np.mean(number_of_peaks_base)\n",
    "n_peaks_base_std = np.std(number_of_peaks_base)\n",
    "heights_counts = []\n",
    "widths_counts = []\n",
    "for peak_height in peak_heights_base:\n",
    "    hist, bin_edges = np.histogram(peak_height, bins=bins_heights)\n",
    "    heights_counts.append(hist)\n",
    "for peak_width in peak_widths_base:\n",
    "    hist, bin_edges = np.histogram(peak_width, bins=bins_width)\n",
    "    widths_counts.append(hist)\n",
    "heights_counts_mean = np.mean(heights_counts, axis=0)\n",
    "heights_counts_std = np.std(heights_counts, axis=0)\n",
    "widths_counts_mean = np.mean(widths_counts, axis=0)\n",
    "widths_counts_std = np.std(widths_counts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▊                                                               | 2/10 [35:46<2:24:16, 1082.05s/it]"
     ]
    }
   ],
   "source": [
    "res_dic = {}\n",
    "factors_arr = [5e-1, 5e0]\n",
    "for factors in factors_arr:\n",
    "    atten_copy = np.copy(atten_vals)\n",
    "    atten_copy = atten_copy * factors\n",
    "    number_of_peaks, peak_heights, peak_widths = evaluation(atten_copy, run_counts)\n",
    "    res_dic[factors] = [number_of_peaks, peak_heights, peak_widths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(res_dic, open(\"comp_sim.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals_peaks = {}\n",
    "mean_vals_heights = {}\n",
    "mean_vals_widths = {}\n",
    "for id_fac, factors in enumerate(factors_arr):\n",
    "    mean_vals_peaks[factors] = np.mean(res_dic[factors][0])\n",
    "    heights = []\n",
    "    widths = []\n",
    "    for peak_height in res_dic[factors][1]:\n",
    "        hist, bin_edges = np.histogram(peak_height, bins=bins_heights)\n",
    "        heights.append(hist)\n",
    "    for peak_width in res_dic[factors][2]:\n",
    "        hist, bin_edges = np.histogram(peak_width, bins=bins_width)\n",
    "        widths.append(hist)\n",
    "    mean_vals_heights[factors] = np.mean(heights, axis=0)\n",
    "    mean_vals_widths[factors] = np.mean(widths, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_peaks_base_mean)\n",
    "for factors in factors_arr:\n",
    "    print(mean_vals_peaks[factors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, (ax1) = plt.subplots(1, 1, figsize=(std_size, std_size * 6. / 8.), sharex=True)\n",
    "for factors in factors_arr:\n",
    "    ax1.plot(np.sqrt(bins_heights[1:] * bins_heights[:-1]), mean_vals_heights[factors])\n",
    "ax1.plot(np.sqrt(bins_heights[1:] * bins_heights[:-1]), heights_counts_mean, color='k')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('linear')\n",
    "ax1.set_xlabel(r'$\\mathrm{Heights}$', fontsize=fontsize)\n",
    "ax1.set_ylabel(r'$\\mathrm{Counts}$', fontsize=fontsize)\n",
    "ax1.tick_params(axis = 'both', which = 'major', labelsize=fontsize, direction='in')\n",
    "ax1.tick_params(axis = 'both', which = 'minor', labelsize=fontsize, direction='in')\n",
    "# ax1.grid(True)\n",
    "h, l = ax1.get_legend_handles_labels()\n",
    "lgd1 = ax1.legend(h,l, loc=9, bbox_to_anchor=(0.5, +1.4),\n",
    "                  ncol=2, fontsize=fontsize, handlelength=h_length,\n",
    "                  fancybox=True, frameon=False)\n",
    "# ax1.set_ylim(1e0, 1e6)\n",
    "# ax1.set_xlim(1e3, 1e6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, (ax1) = plt.subplots(1, 1, figsize=(std_size, std_size * 6. / 8.), sharex=True)\n",
    "for factors in factors_arr:\n",
    "    ax1.plot((bins_width[1:] + bins_width[:-1])/2, mean_vals_widths[factors])\n",
    "ax1.plot((bins_width[1:] + bins_width[:-1])/2, widths_counts_mean, color='k')\n",
    "ax1.set_xscale('linear')\n",
    "ax1.set_yscale('linear')\n",
    "ax1.set_xlabel(r'$\\mathrm{Widths}$', fontsize=fontsize)\n",
    "ax1.set_ylabel(r'$\\mathrm{Counts}$', fontsize=fontsize)\n",
    "ax1.tick_params(axis = 'both', which = 'major', labelsize=fontsize, direction='in')\n",
    "ax1.tick_params(axis = 'both', which = 'minor', labelsize=fontsize, direction='in')\n",
    "# ax1.grid(True)\n",
    "h, l = ax1.get_legend_handles_labels()\n",
    "lgd1 = ax1.legend(h,l, loc=9, bbox_to_anchor=(0.5, +1.4),\n",
    "                  ncol=2, fontsize=fontsize, handlelength=h_length,\n",
    "                  fancybox=True, frameon=False)\n",
    "# ax1.set_ylim(1e0, 1e6)\n",
    "# ax1.set_xlim(0., 20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
